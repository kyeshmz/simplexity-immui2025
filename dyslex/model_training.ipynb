{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming data to CSV files (replacing comma by semicolon)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:24:24.294178Z",
     "start_time": "2025-04-07T22:24:22.367908Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Constants of the data-file format\n",
    "DATA_FILE_EXT = '.csv'\n",
    "data_version_dir = \"v3.0\"\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_BASE_DIR = os.path.join(BASE_DIR, \"data\", \"experiment-final\", data_version_dir)\n",
    "\n",
    "in_data_dir = os.path.join(DATA_BASE_DIR, \"original-patched\")\n",
    "out_data_dir = os.path.join(DATA_BASE_DIR, \"original-csv\")\n",
    "out_data_extracted_features_dir = os.path.join(DATA_BASE_DIR, \"extracted_features\")\n",
    "out_data_fixation_images_dir = os.path.join(DATA_BASE_DIR, \"fixation_images\")\n",
    "out_models_dir = os.path.join(DATA_BASE_DIR, \"models\")\n",
    "out_results_dir = os.path.join(DATA_BASE_DIR, \"results\")\n",
    "\n",
    "print(\"‚úÖ Input data path:\", in_data_dir)\n",
    "print(\"üìÑ Files found:\", os.listdir(in_data_dir)[:5])\n",
    "\n",
    "# in_data_dir = f\"y:/datasets/dyslex/experiment-final/{data_version_dir}/original/\"\n",
    "# out_data_dir = f\"y:/datasets/dyslex/experiment-final/{data_version_dir}/original-csv/\"\n",
    "# out_data_extracted_features_dir = f\"y:/datasets/dyslex/experiment-final/{data_version_dir}/extracted_features/\"\n",
    "# out_data_fixation_images_dir = f\"y:/datasets/dyslex/experiment-final/{data_version_dir}/fixation_images/\"\n",
    "# out_models_dir = f\"y:/trials/xsedmid/dyslex/experiment-final/{data_version_dir}/models/\"\n",
    "# out_results_dir = f\"y:/trials/xsedmid/dyslex/experiment-final/{data_version_dir}/results/\"\n",
    "\n",
    "fill_null_values_by_zero = True\n",
    "summarize_characteristics_by_mean = True\n",
    "#summarize_characteristics_by_mean = False\n",
    "normalize_values = False\n",
    "#normalize_values = True\n",
    "regenerate_fixation_images = True\n",
    "#regenerate_fixation_images = False\n",
    "generate_fixation_image_for_each_trialid = False\n",
    "train_models_MLP = True\n",
    "train_models_CNN = True\n",
    "retrain_models = True\n",
    "\n",
    "data_files = os.listdir(in_data_dir)\n",
    "data_files = list(filter(lambda f: f.lower().endswith(DATA_FILE_EXT.lower()), data_files))\n",
    "print('File count: {}'.format(len(data_files)))\n",
    "\n",
    "# Convert input csv-like files from comma to semicolon separated values\n",
    "if False:\n",
    "    print('Converting files from comma to semicolon separated values')\n",
    "    for f in data_files:\n",
    "        \n",
    "        # Replace comma with semicolon in each file\n",
    "        df = pd.read_csv(os.path.join(in_data_dir, f), skiprows=0, sep=',')\n",
    "        print(f)\n",
    "        df.to_csv(os.path.join(out_data_dir, f), sep=';', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Input data path: /Users/heyutian/Documents/For transfer to hard disk/11_Grad School/MIT_2025_Spring_Semester/6_8510/TermProject/Eye_Tracking/Git_Repo_Downloads/simplexity-immui2025/dyslex/data/experiment-final/v3.0/original-patched\n",
      "üìÑ Files found: ['1040_T5_metrics.csv', '1082_T5_fixations.csv', '1038_T4_fixations.csv', '1476_T4_metrics.csv', '1174_T4_metrics.csv']\n",
      "File count: 420\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing .CSV files and transforming task-related features into internal representations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:24:24.967054Z",
     "start_time": "2025-04-07T22:24:24.418572Z"
    }
   },
   "source": [
    "import feature_extractor as feat_ext\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Read task-invariant properties from a json file\n",
    "with open('properties.json') as property_file:\n",
    "    properties = json.loads(property_file.read())\n",
    "\n",
    "# Path to directory with metainformation about the dataset and features for individual tasks\n",
    "meta_dir = properties['meta_dir']\n",
    "\n",
    "aoi_id_col_name = properties['aoi_id_col_name']\n",
    "subject_id_col_name = properties['subject_id_col_name']\n",
    "degrees_visual_angle_pixels = properties['degrees_visual_angle_pixels']\n",
    "\n",
    "# Fixation image parameters\n",
    "fixation_image_characteristics_names = [\n",
    "    properties['fixation_image_fix_x_col_name'],\n",
    "    properties['fixation_image_fix_y_col_name'],\n",
    "    properties['fixation_image_disp_x_col_name'],\n",
    "    properties['fixation_image_disp_y_col_name'],\n",
    "    properties['fixation_image_duration_ms_col_name']\n",
    "    ]\n",
    "fixation_image_visual_params = eval(properties['fixation_image_visual_params'])\n",
    "\n",
    "# Task definitions\n",
    "tasks_def = eval(properties['tasks'])\n",
    "task_feature_def_dict = feat_ext.load_task_feature_definition_dict(tasks_def, meta_dir)\n",
    "task_definitions = [(task['type_id'], task['desc'], task['id']) for task in tasks_def]\n",
    "\n",
    "# for task_type_id, task_desc, task_id in task_definitions:\n",
    "#     data_dict = {}\n",
    "#\n",
    "#     ###############################################################################################################\n",
    "#     # Global characteristics\n",
    "#     ###############################################################################################################\n",
    "#     # Read the metric data files for the task\n",
    "#     subject_metrics_files = os.listdir(in_data_dir)\n",
    "#     subject_metrics_files = list(filter(lambda file_name: file_name.lower().endswith(('_' + task_id + '_metrics' + DATA_FILE_EXT).lower()), subject_metrics_files))\n",
    "#     print('* file count: {}'.format(len(subject_metrics_files)))\n",
    "\n",
    "# # üîç Isolate T4 only\n",
    "# for task_type_id, task_desc, task_id in task_definitions:\n",
    "#     if task_id != \"T4\":\n",
    "#         continue  # Skip everything except T4\n",
    "#\n",
    "#     print(f\"\\nüöÄ Processing Task {task_id} - {task_desc}\")\n",
    "#\n",
    "#     data_dict = {}\n",
    "#\n",
    "#     # Normalize the dictionary data independently for each type of characteristics\n",
    "#     if normalize_values:\n",
    "#         for (characteristics_name, columns) in [('characteristics_global', task_feature_def_dict[task_type_id]['characteristics_global']), ('characteristics', task_feature_def_dict[task_type_id]['characteristics']), ('AOIs_characteristics', task_feature_def_dict[task_type_id]['aoi_characteristics'])]:\n",
    "#             if (columns is not None):\n",
    "#                 print(f'* normalization-{characteristics_name}:')\n",
    "#                 #for column in columns:\n",
    "#                 for column in data_dict[subject_id][characteristics_name].columns:\n",
    "#\n",
    "#                     # Get the values of the characteristic for all subjects\n",
    "#                     all_characteristics_values = [data_dict[subject_id][characteristics_name][column].values for subject_id in data_dict.keys()]\n",
    "#                     # Flatten the list of values\n",
    "#                     all_characteristics_values = [value for sublist in all_characteristics_values for value in sublist]\n",
    "#                     # Get the mean and standard deviation of the values\n",
    "#                     mean = np.mean(all_characteristics_values)\n",
    "#                     std = np.std(all_characteristics_values)\n",
    "#                     # Normalize the values for each subject\n",
    "#                     for subject_id in data_dict.keys():\n",
    "#                         data_dict[subject_id][characteristics_name].loc[:, column] = data_dict[subject_id][characteristics_name][column].apply(lambda x: (x - mean) / std)\n",
    "#                     print(f'  - {column}:{len(all_characteristics_values)}: {mean} +/- {std}')\n",
    "#\n",
    "#     # Flatten the dictionary data\n",
    "#     df_fixations_all = []\n",
    "#     for subject_id in data_dict.keys():\n",
    "#         df_fixations_all.append(feat_ext.create_subject_characteristics_profile(subject_id, data_dict[subject_id]))\n",
    "#     df_fixations_all = pd.concat(df_fixations_all, axis=0)\n",
    "#     print(f'final df: {df_fixations_all.shape}')\n",
    "#     out_file_name = os.path.join(out_data_extracted_features_dir, task_type_id + '_' + task_desc + '_features' + DATA_FILE_EXT)\n",
    "#     df_fixations_all.to_csv(out_file_name, sep=';', index=False)\n",
    "\n",
    "# üîç Isolate T4 only\n",
    "for task_type_id, task_desc, task_id in task_definitions:\n",
    "    if task_id != \"T4\":\n",
    "        continue  # Skip everything except T4\n",
    "\n",
    "    print(f\"\\nüöÄ Processing Task {task_id} - {task_desc}\")\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Load metric files for this task\n",
    "    ###############################################################################################################\n",
    "    subject_metrics_files = os.listdir(in_data_dir)\n",
    "    subject_metrics_files = list(filter(\n",
    "        lambda file_name: file_name.lower().endswith(f\"_{task_id}_metrics.csv\".lower()),\n",
    "        subject_metrics_files\n",
    "    ))\n",
    "    print(f'* file count for {task_id}: {len(subject_metrics_files)}')\n",
    "\n",
    "    for file_name in subject_metrics_files:\n",
    "        subject_id, subject_data_dict = feat_ext.load_and_transform_subject_characteristics(\n",
    "            task_type_id,\n",
    "            task_feature_def_dict,\n",
    "            fill_null_values_by_zero,\n",
    "            subject_id_col_name,\n",
    "            aoi_id_col_name,\n",
    "            summarize_characteristics_by_mean,\n",
    "            os.path.join(in_data_dir, file_name)\n",
    "        )\n",
    "        data_dict[subject_id] = subject_data_dict\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Normalize (optional)\n",
    "    ###############################################################################################################\n",
    "    if normalize_values:\n",
    "        for (characteristics_name, columns) in [\n",
    "            ('characteristics_global', task_feature_def_dict[task_type_id]['characteristics_global']),\n",
    "            ('characteristics', task_feature_def_dict[task_type_id]['characteristics']),\n",
    "            ('AOIs_characteristics', task_feature_def_dict[task_type_id]['aoi_characteristics'])\n",
    "        ]:\n",
    "            if columns is not None:\n",
    "                print(f'* normalization-{characteristics_name}:')\n",
    "                for column in data_dict[subject_id][characteristics_name].columns:\n",
    "                    all_vals = [\n",
    "                        data_dict[sub_id][characteristics_name][column].values\n",
    "                        for sub_id in data_dict.keys()\n",
    "                    ]\n",
    "                    all_vals = [v for sublist in all_vals for v in sublist]\n",
    "                    mean, std = np.mean(all_vals), np.std(all_vals)\n",
    "                    for sub_id in data_dict.keys():\n",
    "                        data_dict[sub_id][characteristics_name].loc[:, column] = data_dict[sub_id][characteristics_name][column].apply(lambda x: (x - mean) / std)\n",
    "                    print(f'  - {column}: {mean:.2f} ¬± {std:.2f}')\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Flatten features and save to CSV\n",
    "    ###############################################################################################################\n",
    "    df_fixations_all = []\n",
    "    for subject_id in data_dict.keys():\n",
    "        df_fixations_all.append(feat_ext.create_subject_characteristics_profile(subject_id, data_dict[subject_id]))\n",
    "\n",
    "    if df_fixations_all:\n",
    "        df_fixations_all = pd.concat(df_fixations_all, axis=0)\n",
    "        print(f'‚úÖ Final df shape: {df_fixations_all.shape}')\n",
    "\n",
    "        out_file_name = os.path.join(out_data_extracted_features_dir, f\"{task_id}_{task_desc}_features.csv\")\n",
    "        df_fixations_all.to_csv(out_file_name, sep=';', index=False)\n",
    "        print(f'üíæ Saved extracted features to: {out_file_name}')\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No data extracted!\")\n",
    "\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Fixation images\n",
    "    ###############################################################################################################\n",
    "    regenerate_fixation_images = False\n",
    "\n",
    "    # if regenerate_fixation_images:\n",
    "    #     print(f'* generating fixation images...')\n",
    "    #     subject_fixations_files = os.listdir(in_data_dir)\n",
    "    #     subject_fixations_files = list(filter(lambda file_name: file_name.lower().endswith(('_' + task_type_id + '_' + task_desc + '_fixations' + DATA_FILE_EXT).lower()), subject_fixations_files))\n",
    "    #\n",
    "    #     # Task-related fixation image visual parameters\n",
    "    #     x_min, x_max, y_min, y_max, d_max = fixation_image_visual_params[task_type_id]\n",
    "    #     fixation_duration_color_norm = Normalize(0, d_max)\n",
    "    #\n",
    "    #     df_fixations_all = []\n",
    "    #     for file_name in subject_fixations_files:\n",
    "    #\n",
    "    #         subject_fixations_file_path = os.path.join(in_data_dir, file_name)\n",
    "    #         subject_id, figs_dict, df_subject_fixations = feat_ext.generate_subject_fixation_images(generate_fixation_image_for_each_trialid, fixation_image_characteristics_names, fill_null_values_by_zero, subject_id_col_name, degrees_visual_angle_pixels, fixation_duration_color_norm, x_min, x_max, y_min, y_max, subject_fixations_file_path)\n",
    "    #\n",
    "    #         for df in df_subject_fixations:\n",
    "    #             df_fixations_all.append(df)\n",
    "    #\n",
    "    #         # Saves the fixation images\n",
    "    #         for trial_id in figs_dict.keys():\n",
    "    #             feat_ext.save_fixation_image(figs_dict[trial_id], out_data_fixation_images_dir, task_id, subject_id, trial_id)\n",
    "\n",
    "        # # Print the minimum and maximum values of individual task-related fixation features\n",
    "        # df_fixations_all = pd.concat(df_fixations_all, axis=0)\n",
    "        # for column in df_fixations_all.columns:\n",
    "        #     print(f'  - {column}: min={df_fixations_all[column].min():.2f}; max={df_fixations_all[column].max():.2f}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* AOI characteristics: 5, AOIs: 90\n",
      "* characteristics-global: 2\n",
      "* characteristics: 3, expected line count: 60\n",
      "* characteristics-global: 3\n",
      "* characteristics: 2, expected line count: 60\n",
      "* characteristics-global: 6\n",
      "* AOI characteristics: 4, AOIs: 7\n",
      "* characteristics-global: 6\n",
      "* AOI characteristics: 4, AOIs: 7\n",
      "* AOI characteristics: 5, AOIs: 55\n",
      "* AOI characteristics: 5, AOIs: 55\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:24:26.177182Z",
     "start_time": "2025-04-07T22:24:24.982064Z"
    }
   },
   "source": [
    "from models import MLP, binary_resnet18, binary_resnet50\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from typing import Dict\n",
    "from utils import cross_validate_sklearn\n",
    "from utils import cross_validate_pytorch\n",
    "from utils import build_global_statistics_data_loader, build_fixation_visualisation_data_loader, create_image_folder_dataset, get_cross_validate_pytorch_model_path\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "class_count = 2\n",
    "training_param_cv_split_count = 5\n",
    "\n",
    "# training_param_kNN_k_values = [3]\n",
    "training_param_kNN_k_values = [1, 3, 4, 5, 10]\n",
    "\n",
    "training_param_MLP_layer_feature_size_decrease = 2\n",
    "#training_param_MLP_layer_count_values = [2]\n",
    "training_param_MLP_layer_count_values = [1, 2]\n",
    "#training_param_MLP_drop_values = [0.2, 0.5]\n",
    "training_param_MLP_drop_values = [0.0, 0.2, 0.5]\n",
    "training_param_MLP_epoch_count_values = [10, 20]\n",
    "training_param_MLP_lr_values = [0.1, 0.05]\n",
    "\n",
    "#training_param_CNN_epoch_count_values = [20, 50]\n",
    "training_param_CNN_epoch_count_values = [100]\n",
    "training_param_CNN_lr_values = [0.001, 0.0001, 0.00001]\n",
    "\n",
    "cross_validation = RepeatedStratifiedKFold(n_splits=training_param_cv_split_count, n_repeats=1, random_state=42)\n",
    "\n",
    "# Read a class_id-class_label dictionary from a csv file\n",
    "df_class_labels = pd.read_csv(os.path.join(meta_dir, 'class_ids.txt'), skiprows=0, sep=',')\n",
    "\n",
    "# Read the names of characteristics-global if the file exists\n",
    "subject_class_mapping = pd.read_csv(os.path.join(meta_dir, 'subject_class_mapping-' + data_version_dir + '.txt'), skiprows=0, sep=',')\n",
    "\n",
    "task_data : Dict[str, pd.DataFrame] = {}\n",
    "for task_type_id, task_desc, task_id in task_definitions:\n",
    "    if task_id != \"T4\":\n",
    "        continue\n",
    "    print('#' * 80)\n",
    "    print(f'Processing task: {task_type_id} ({task_desc})')\n",
    "\n",
    "    task_data_file_name = os.path.join(out_data_extracted_features_dir, task_id + '_features' + DATA_FILE_EXT)\n",
    "    task_data[task_type_id] = pd.read_csv(task_data_file_name, skiprows=0, sep=';')#, dtype=np.float64\n",
    "    \n",
    "    # Join the data with the subject class mapping\n",
    "    task_subject_class_mapping = task_data[task_type_id].merge(subject_class_mapping, on='subject_id', how='left')[['subject_id', 'class_id']]\n",
    "\n",
    "    df_subject_ids = task_data[task_type_id]['subject_id']\n",
    "    X = task_data[task_type_id].drop('subject_id', axis=1).astype(np.float64)\n",
    "    y = task_subject_class_mapping['class_id']\n",
    "        \n",
    "    # Get the feature count\n",
    "    print(f'Feature count: {len(X.columns)}')\n",
    "    n_features = len(X.columns)\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # kNN\n",
    "    ###############################################################################################################\n",
    "\n",
    "    # kNN with default parameters (p=2, metric='minkowski') results in the Euclidean distance comparison\n",
    "    for training_param_kNN_k in training_param_kNN_k_values:\n",
    "        # kNN with all objects (i.e., no cross-validation) and standard (not-balanced) accuracy\n",
    "        exp_id = f'{task_type_id}_{task_desc}_{training_param_kNN_k}NN'\n",
    "        knn = KNeighborsClassifier(n_neighbors=training_param_kNN_k)\n",
    "        knn.fit(X, np.asarray(y.values))\n",
    "        X_preds = knn.predict(X)\n",
    "        print(f'{training_param_kNN_k}NN-all-!BA : {accuracy_score(y.values, X_preds):.4f}')\n",
    "        #print(f'acc.: {torch.sum(torch.tensor(X_preds) == torch.tensor(y.values)) / len(X_preds)}')\n",
    "\n",
    "        # # kNN with cross-validation -- an alternative implementation for verification\n",
    "        # scores = cross_val_score(\n",
    "        #     knn,\n",
    "        #     X,\n",
    "        #     y=np.asarray(y.values),\n",
    "        #     scoring = 'balanced_accuracy',\n",
    "        #     cv=cross_validation,\n",
    "        # )\n",
    "        # print(f'{training_param_kNN_k}NN         : {scores.mean():.4f} +/- {scores.std():.4f}')\n",
    "\n",
    "        # kNN without the scaler\n",
    "        scores = cross_validate_sklearn(\n",
    "            exp_id + '_without_scaler',\n",
    "            out_models_dir,\n",
    "            out_results_dir,\n",
    "            lambda: KNeighborsClassifier(n_neighbors=training_param_kNN_k),\n",
    "            X,\n",
    "            np.asarray(y),\n",
    "            df_subject_ids,\n",
    "            df_class_labels,\n",
    "            cross_validation,\n",
    "            use_scaler=False\n",
    "        )\n",
    "        print(f'{training_param_kNN_k}NN no scaler: {scores.mean():.4f} +/- {scores.std():.4f}')\n",
    "\n",
    "        # kNN with the scaler\n",
    "        scores = cross_validate_sklearn(\n",
    "            exp_id + '_with_scaler',\n",
    "            out_models_dir,\n",
    "            out_results_dir,\n",
    "            lambda: KNeighborsClassifier(n_neighbors=training_param_kNN_k),\n",
    "            X,\n",
    "            np.asarray(y),\n",
    "            df_subject_ids,\n",
    "            df_class_labels,\n",
    "            cross_validation,\n",
    "            use_scaler=True\n",
    "        )\n",
    "        print(f'{training_param_kNN_k}NN scaler  : {scores.mean():.4f} +/- {scores.std():.4f}')\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # MLP\n",
    "    ###############################################################################################################\n",
    "\n",
    "    if train_models_MLP:\n",
    "        for training_param_MLP_layer_count in training_param_MLP_layer_count_values:\n",
    "            for training_param_MLP_drop in training_param_MLP_drop_values:\n",
    "                for training_param_epoch_count in training_param_MLP_epoch_count_values:\n",
    "                    for training_param_lr in training_param_MLP_lr_values:\n",
    "                        exp_id = f'{task_type_id}_{task_desc}_MLP_lc{training_param_MLP_layer_count}_lf{training_param_MLP_layer_feature_size_decrease}_d{training_param_MLP_drop}'\n",
    "                        if retrain_models or (not os.path.exists(get_cross_validate_pytorch_model_path(out_models_dir, exp_id, training_param_epoch_count, training_param_lr))):\n",
    "                            scores, cv_score_best = cross_validate_pytorch(\n",
    "                                exp_id,\n",
    "                                out_models_dir,\n",
    "                                out_results_dir,\n",
    "                                lambda: MLP(n_features, n_features // training_param_MLP_layer_feature_size_decrease, class_count, training_param_MLP_layer_count, training_param_MLP_drop),\n",
    "                                training_param_epoch_count,\n",
    "                                training_param_lr,\n",
    "                                X,\n",
    "                                np.asarray(y),\n",
    "                                df_subject_ids,\n",
    "                                df_class_labels,\n",
    "                                build_global_statistics_data_loader,\n",
    "                                cross_validation,\n",
    "                                train_classifier=True\n",
    "                            )\n",
    "                            print(f'MLP-lc{training_param_MLP_layer_count}-d{training_param_MLP_drop}-e{training_param_epoch_count}_lr{training_param_lr}         : {scores.mean():.4f} +/- {scores.std():.4f} (best epoch: {cv_score_best:.4f})')\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # Fixation images\n",
    "    ###############################################################################################################\n",
    "    image_dir = os.path.join(out_data_fixation_images_dir, task_type_id + '_' + task_desc)\n",
    "    image_filenames = [filename for filename in os.listdir(image_dir) if any(filename.lower().endswith(ext) for ext in '.png')]\n",
    "    image_paths = [os.path.join(image_dir, filename) for filename in image_filenames]\n",
    "    image_subject_ids = [int(filename.split('_')[0]) for filename in image_filenames]\n",
    "    \n",
    "    df_image_subject_class_ids = pd.DataFrame({'subject_id': image_subject_ids}).merge(subject_class_mapping, on='subject_id', how='left')[['subject_id', 'class_id']]\n",
    "    df_image_subject_ids = df_image_subject_class_ids['subject_id']\n",
    "    df_image_class_ids = df_image_subject_class_ids['class_id']\n",
    "    \n",
    "    image_dataset = create_image_folder_dataset(image_paths, df_image_class_ids.values)\n",
    "\n",
    "    ###############################################################################################################\n",
    "    # CNNs\n",
    "    ###############################################################################################################\n",
    "    if train_models_CNN:\n",
    "        for training_param_epoch_count in training_param_CNN_epoch_count_values:\n",
    "            for training_param_lr in training_param_CNN_lr_values:\n",
    "\n",
    "                exp_id = f'{task_type_id}_{task_desc}_ResNet18'\n",
    "                if retrain_models or (not os.path.exists(get_cross_validate_pytorch_model_path(out_models_dir, exp_id, training_param_epoch_count, training_param_lr))):\n",
    "                    scores, cv_score_best = cross_validate_pytorch(\n",
    "                        exp_id,\n",
    "                        out_models_dir,\n",
    "                        out_results_dir,\n",
    "                        binary_resnet18,\n",
    "                        training_param_epoch_count,\n",
    "                        training_param_lr,\n",
    "                        image_paths,\n",
    "                        np.asarray(df_image_class_ids.values),\n",
    "                        df_image_subject_ids,\n",
    "                        df_class_labels,\n",
    "                        build_fixation_visualisation_data_loader,\n",
    "                        cross_validation,\n",
    "                        train_classifier=True,\n",
    "                        dataset=image_dataset\n",
    "                    )\n",
    "                    print(f'ResNet18-e{training_param_epoch_count}_lr{training_param_lr}    : {scores.mean():.4f} +/- {scores.std():.4f} (best epoch: {cv_score_best:.4f})')\n",
    "\n",
    "                exp_id = f'{task_type_id}_{task_desc}_ResNet50'\n",
    "                if retrain_models or (not os.path.exists(get_cross_validate_pytorch_model_path(out_models_dir, exp_id, training_param_epoch_count, training_param_lr))):\n",
    "                    scores, cv_score_best = cross_validate_pytorch(\n",
    "                        exp_id,\n",
    "                        out_models_dir,\n",
    "                        out_results_dir,\n",
    "                        binary_resnet50,\n",
    "                        training_param_epoch_count,\n",
    "                        training_param_lr,\n",
    "                        image_paths,\n",
    "                        np.asarray(df_image_class_ids.values),\n",
    "                        df_image_subject_ids,\n",
    "                        df_class_labels,\n",
    "                        build_fixation_visualisation_data_loader,\n",
    "                        cross_validation,\n",
    "                        train_classifier=True,\n",
    "                        dataset=image_dataset\n",
    "                    )\n",
    "                    print(f'ResNet50-e{training_param_epoch_count}_lr{training_param_lr}    : {scores.mean():.4f} +/- {scores.std():.4f} (best epoch: {cv_score_best:.4f})')\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-07T22:24:26.376542Z",
     "start_time": "2025-04-07T22:24:26.182301Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "plot_dict: Dict = {}\n",
    "approach_names = []\n",
    "for task_type_id, task_desc, task_id in task_definitions:\n",
    "    if task_id != \"T4\":\n",
    "        continue\n",
    "    task_file_prefix = task_id + '_'\n",
    "\n",
    "    results_files = os.listdir(out_results_dir)\n",
    "    results_files = list(filter(lambda f: f.lower().startswith(task_file_prefix.lower()) and f.lower().endswith(DATA_FILE_EXT.lower()), results_files))\n",
    "    for result_file in results_files:\n",
    "\n",
    "        # Get the approach name from the file name\n",
    "        approach_name = result_file[len(task_file_prefix):-len(DATA_FILE_EXT)]\n",
    "        approach_names.append(approach_name)\n",
    "\n",
    "        df = pd.read_csv(os.path.join(out_results_dir, result_file), skiprows=0, sep=',')\n",
    "\n",
    "        # Convert column values to a numpy array\n",
    "        targets = np.asarray(df['subject_class_id'].values)\n",
    "        preds = np.asarray(df['pred_class_id'].values)\n",
    "\n",
    "        # Compute the number of different values and their counts in targets and preds\n",
    "        target_values, target_values_counts = np.unique(targets, return_counts=True)\n",
    "        pred_values, pred_values_counts = np.unique(preds, return_counts=True)\n",
    "\n",
    "        # Split targets and predictions into batches of a fixed size\n",
    "        batch_size = targets.size / training_param_cv_split_count\n",
    "        targets_batches = np.array_split(targets, len(targets) // batch_size)\n",
    "        preds_batches = np.array_split(preds, len(preds) // batch_size)\n",
    "\n",
    "        # Calculate the balanced accuracy score for each batch\n",
    "        scores = []\n",
    "        for i, (target_batch, pred_batch) in enumerate(zip(targets_batches, preds_batches)):\n",
    "            scores.append(balanced_accuracy_score(target_batch, pred_batch))\n",
    "        # Print the mean and standard deviation of the balanced accuracy scores\n",
    "        print(f'{result_file}: {np.mean(scores):.4f} +/- {np.std(scores):.4f} (predicted classes: {pred_values}; counts: {pred_values_counts})')\n",
    "\n",
    "        # Add the score to the plot dictionary\n",
    "        plot_dict[(task_id, approach_name)] = np.mean(scores)\n",
    "\n",
    "# Make the approach names unique\n",
    "approach_names = list(set(approach_names))\n",
    "\n",
    "#df_plot = pd.DataFrame()\n",
    "fig, ax = plt.subplots(figsize=(5, 4), layout='constrained')\n",
    "\n",
    "# Get numpy array from task ids\n",
    "# task_ids_np = np.array([task_id for task_type_id, task_desc, task_id in task_definitions])\n",
    "task_ids_np = np.array([\"T4\"])\n",
    "\n",
    "# Generate the plot for each approach\n",
    "for approach_name in approach_names:\n",
    "    scores = []\n",
    "    for task_type_id, task_desc, task_id in task_definitions:\n",
    "        scores.append(plot_dict[(task_id, approach_name)] if (task_id, approach_name) in plot_dict else 0)\n",
    "    #ax.scatter(task_ids_np, scores, s=100, alpha=0.5, label=approach_name)\n",
    "    ax.plot(task_ids_np, scores, label=approach_name)\n",
    "\n",
    "print(\"üìä Plotting scores:\")\n",
    "for approach_name in approach_names:\n",
    "    scores = []\n",
    "    for task_id in task_ids_np:\n",
    "        score = plot_dict.get((task_id, approach_name), None)\n",
    "        print(f\" - {approach_name} on {task_id}: {score}\")\n",
    "        if score is not None:\n",
    "            scores.append(score)\n",
    "    if scores:\n",
    "        ax.plot(task_ids_np, scores, label=approach_name)\n",
    "\n",
    "# Rotate the x-axis labels\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('Tasks')\n",
    "ax.set_ylabel('Balanced accuracy (%)')\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Plotting scores:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Balanced accuracy (%)')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "258767ba04530a691d36ec1007403c0ecaef04345e31a8f5d6dd0ea972e939a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
